<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Raj Ratn Pranesh Academic Page" />
    <link rel="stylesheet" href="css/main.css" />
    <link rel="icon" href="img/umlogo.png">
    <title>Raj Ratn Pranesh</title>
  </head>
  <body>
    <header>
      <div class="container header-inner">
        <h1 class="name">
          Raj Ratn Pranesh
        </h1>
        <nav>
          <ul>
            <li><a href="#publications">Publications</a></li>
            <li><a href="#experience">Experience</a></li>
            <li><a href="#suggestedlinks">Good Advice</a></li>
            <li><a href="https://drive.google.com/file/d/1GTkW_c-teOlh_QScmOjMZWWHkR_3p-MI/view?usp=sharing" target="_blank">CV</a></li>
            <li><a href="blog.html" target="_blank">Miscellaneous</a></li>
          </ul>
        </nav>
      </div>
    </header>
    <main>
      <section id="about" class="py-1">
        <div class="container about-inner">
          <div class="about-desc">
            <p class="pb-1">
              I'm Raj, a final year <strong>undergrad student</strong> in Computer Science and Engineering at the <strong>Birla Institute of Technology, Mesra</strong></a>. I'm a researcher and a developer, passionate about researh works and developing new skills.
            </p>
            <div class="contact-info">
              <a href="mailto:raj.ratn18@gmail.com">raj.ratn18@gmail.com</a>
              <!-- <span>||</span>
              <a href="mailto:raj.ratn18@gmail.com"
                >raj.ratn18@gmail.com</a
              > -->
              <span>||</span>
              <a href="https://www.linkedin.com/in/raj-ratn-pranesh-382155172/">LinkedIn</a>
              <span>||</span>
              <a href="https://github.com/Rajratnpranesh">GitHub</a>
              <span>||</span>
              <a href="https://scholar.google.com/citations?user=tLBG408AAAAJ&hl=en"
                >Google Scholar</a
              >
              <!--<span>||</span>
              <a
                href="https://drive.google.com/file/d/114a9vX3dpjajZa9isMDg_d294-v-FcZ7/view?usp=sharing&authuser=0" target="_blank"
                >CV</a
              >-->
            </div>
            <div class="research">
              <h1 class="heading-m">
                Research interests
              </h1>
              <p class="pb-1">
				I have worked in related fields like machine learning, artificial intelligence, software engineering, internet of things and data mining. I strive to contribute in machine learning fields as the concept and large applicabilty of machine learning fascinates my curious mind and provides a space to come up with my own ideas.

				"Growth occurs when one goes beyond one's limit. Realizing that is also a part of the training."
				I enjoy learning new and keep moving forward so that I could acquire as much as I could get. I consider work as an ongoing process, and I'm always looking for opportunities to work with those who are willing to share their knowledge. At the end of the day, my primary goal is to work hard and gather knowledge.
				</span>
              </p>
              <p>
                
				When I'm not in front of a computer screen, I'm probably reading books, thinking about robotics, playing football, reading mangas, or cooking.
              </p>
            </div>
          </div>
          <img src="img/Raj.jpg" alt="Mimanas" />
        </div>
      </section>
      <section id="updates" class="py-1">
        <div class="container updates-inner">
          <h1 class="heading-m">
            Updates
          </h1>
          <ul>
			<li>[December 2020] <span style="color:red;font-weight: bold;">[New!]</span> I'll be attending NIPS 2020 online. Come check out our work at MLPH 2020. Shoot me an email if you want to meet and talk about anything!</li>		  
			<li>[November 2020] <span style="color:red;font-weight: bold;">[New!]</span> I'll be attending EMNLP 2020 online. Check out our work on SustainNLP 2020. See you there!</li>
			<li>[October 2020] <span style="color:red;font-weight: bold;">[New!]</span> Paper presenting assemble Q&A language model got accepted at ICCCS 2020. See you there!</li>
            <li>[July 2020] <span style="color:red;font-weight: bold;">[New!]</span> I'll be attending ICML 2020 online. See you there!</li>
            <li>[June 2020] <span style="color:red;font-weight: bold;">[New!]</span> Our paper on OCR table extraction has been accepted to ICDAR 2020.</li>
          </ul>
        </div>
      </section>
      <section id="publications" class="py-1">
        <div class="container publications-inner">
          <h1 class="heading-m"> Publications</h1>
          <div class="submitted">
            <h2 class="heading-s ml-1">Submitted papers</h2>
            <ul>
              <li>
                <div class="collapsible">
                  <p><span class="bold"> COVID-19 Misinformation on Twitter: Multilingual Analysis</span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Raj Ratn Pranesh</span>, Mehrdad Farokhenajd, Ambesh Shekhar, Genoveva Vargas-Solar
                  <!--<br>Information Systems, Elsevier<br>-->
                    <!--<a href="https://openreview.net/pdf?id=-iAXocQfR7">Paper</a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>This paper presents a multilingual COVID-19 related tweet analysis method, CMTA, that uses BERT, a deep learning model for multilingual tweet misinformation detection and classification. CMTA extracts features from multilingual textual data, which is then categorized into specific information classes. Classification is done by a Dense-CNN model trained on tweets manually annotated into information classes (i.e., ’false’, ’partly false’, ’misleading’).
                </p> </div>
              </li>       
            </ul>
          </div>

          <div class="accepted">
            <h2 class="heading-s ml-1">Accepted Publications</h2>
            <ul>
              <li>
                <div class="collapsible">
                  <p><span class="bold"> A Conglomerate of Multiple OCR Table Detection and Extraction </span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Smita Pallavi, Raj Ratn Pranesh</span>, Sumit Kumar
                  <br>22nd International Conference on Document Analysis and Recognition, 2020<br>
                   <a href="https://arxiv.org/abs/2010.08591">Presentation</a>
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>MInformation representation as tables are compact and concise method that eases searching, indexing, and storage requirements. Extracting and cloning tables from parsable documents is easier and widely used, however industry still faces challenge in detecting and extracting tables from OCR documents or images. This paper proposes an algorithm that detects and extracts multiple tables from OCR document. The algorithm uses a combination of image processing techniques, text recognition and procedural coding to identify distinct tables in same image and map the text to appropriate corresponding cell in dataframe which can be stored as Comma-separated values, Database, Excel and multiple other usable formats.</p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p><span class="bold"> Automated Medical Assistance: Attention Based Consultation System </span></p>
                    <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Raj Ratn Pranesh</span>, Ambesh Shekhar, Sumit Kumar
                    <br>NeurIPS, 2020 MLPH: Machine Learning in Public Health Workshop) 2020<br>
                    <a href="https://drive.google.com/file/d/1_hAzSBimEjbZNGGp4PRoW0jbW207kr9A/view">Paper</a>
                    <!--<span>||</span><a href="">Dataset</a>-->
                  </p></div>
                <div class="content"><p class="py-025"><span class ="bold">TLDR: </span>. TWe designed three
				transformers based encoder-decoder model, namely, BERT, GPT2, and BART and
				trained them on large the dialogue dataset for text generation. We performed a
				comparative study of the models and in our analysis, we found that the BART
				model generates a doctor-like response and contains clinically informative data.
				The overall generated results were very promising and show that through transfer
				learning pre-trained transformers are reliable for developing automated medical
				assistance system and doctor-like-treatments. </p></div>
              </li>

              <li>
                <div class="collapsible">
                  <p><span class="bold"> MemeSem:A Multi-modal Framework for Sentimental Analysis of Meme via Transfer Learning </span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Raj Ratn Pranesh</span>, Ambesh Shekhar
                  <br>37th International Conference on Machine Learning (ICML), 2020 (4th Lifelong Learning Workshop)<br>
                    <a href="https://openreview.net/attachment?id=qHAEGVRlrz9&name=pdf">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>In this paper, we present MemeSem- a multimodal deep neural network framework for sentiment analysis of memes via transfer learning. Our proposed model utilizes VGG19 pretrained on ImageNet dataset and BERT language model to learn the visual and textual feature of the meme and combine them together to make predictions. </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p><span class="bold"> QuesBELM: A BERT based Ensemble Language Model for Natural Questions </span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Raj Ratn Pranesh</span>, Ambesh Shekhar, Smita Pallavi
                  <br> 5th IEEE ICCCS (International Conference) <br>
                    <a href="https://openreview.net/pdf?id=5J3KYvaIw35">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>In our work, we systematically compare the performance of powerful variant models of Transformer architectures- ’BERTbase, BERT-large-WWM and ALBERT-XXL’ over Natural Questions dataset. We also propose a state-of-the-art BERT based ensemble language model- QuesBELM. QuesBELM leverages the power of existing BERT variants combined together to build a more accurate stacking ensemble model for question answering (QA) system </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> Analysis of Resource-efficient Predictive Models for Natural Language Processing </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> <span class="bold">Raj Ratn Pranesh</span>, Ambesh Shekhar
                    <br> EMNLP, 2020 (SustaiNLP Workshop) <br>
                    <a href="https://openreview.net/pdf?id=4Dowguaqed">Paper</a>
                    <!--<span>||</span><a href=""> Slides </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>In this paper, we presented an analyses of the resource efficient predictive models, namely Bonsai, Binary Neighbor Compression(BNC), ProtoNN, Random Forest, Naive Bayes and Support vector machine(SVM), in the machine learning field for resource constraint devices. These models try to minimize resource requirements like RAM and storage without hurting the accuracy much. We utilized these models on multiple benchmark natural language processing tasks, which were sentimental analysis, spam message detection, emotion analysis and fake news classification.</p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> Biomedical Network Link Prediction using Neural Network Graph Embedding </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> Zakaria Aldeneh, <span class="bold">Sumit Kumar, Raj Ratn Pranesh</span>, Ambesh Shekhar
                    <br> ACM CoDS-COMAD, 2020 (Young Researchers’ Symposium) <br>
                    <a href="https://openreview.net/pdf?id=ZsG1W37IbVh">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span> In this paper, we aim at Graph embedding learning for automatic grasping of low-dimensional node representation on biomedical networks. The purpose is to use different neural Graph embedding methods for conducting analysis on 3 major biomedical link prediction tasks: drug-disease association (DDA) prediction, drug-drug interaction (DDI) classification, and protein-protein interaction (PPI) classification. We observe that graph embedding method achieve a promising result without the use of any biological features. </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> Classifying Micro-text Document Datasets: Application to Query Expansion of Crisis-Related Tweets </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> <span class="bold">Mehrdad Farokhen, Raj Ratn Pranesh</span>, Javier A. Espinosa-Oviedo
                    <br> ICSOC, 2020 (STRAPS 2020 Workshop).<br>
                    <a href="https://drive.google.com/file/d/1Ys9WFKMiG4mOGwU8ugU259HSCT-l-hGa/view">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>This paper introduces an approach based on classification and query expansion techniques in the context of micro-texts (i.e., tweets) search. In our approach, a user’s query is rewritten using a classified vocabulary derived from top-k results, to reflect her search intent better.</p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> A Fine-Grained Analysis of Misinformation in COVID-19 Tweets </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> Soheil Khorram, <span class="bold">Sumit Kumar, Raj Ratn Pranesh</span>, Kathleen M. Carle
                    <br> Computational and Mathematical Organization Theory, Springer.<br>
                    <a href="https://drive.google.com/file/d/1BbCM-Pfm8xca6dYe9TJbKAYpIYltDSYs/view">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>In this paper, We have proposed a Twitter dataset for fine-grained classification. Our dataset is consist of 1970 manually annotated tweets and is categorized into 4 misinformation classes, i.e, “Irrelevant”, “Conspiracy”, “True Information”, and “False Information” on the basis of response erupted during COVID-19. In this work, we also generated useful insights on our dataset and performed a systematic analysis of various language models. </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> CLPLM: Character Level Pretrained Language Model for ExtractingSupport Phrases for Sentiment Labels </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> <span class="bold">Raj Ratn Pranesh</span>, Sumit Kumar, Ambesh Shekhar
                    <br> 17th International Conference on Natural Language Processing, 2020.<br>
                    <a href="https://drive.google.com/file/d/1qj-q-oYR18Zvwoxg3CoAwt1VGf-oHlyb/view">Paper</a>
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>In this paper, we have designed a character-level pre-trained language model for extracting support phrases from tweets based on the sentiment label. We also propose a character-level ensemble model designed by properly blending Pre-trained Contextual Embeddings (PCE) models- RoBERTa, BERT, and ALBERT along with Neural network models-RNN, CNN and WaveNet at different stages of the model. For a given tweet and associated sentiment label, our model predicts the span of phrases in a tweet that prompts the particular sentiment in the tweet. </p> </div>
              </li>
            </ul>
          </div>
        </div>

      </section>
      <section id="experience" class="py-1">
        <div class="container experience-inner">
          <!--<h1 class="heading-m">
            Experience
          </h1>-->
          <div class="internship">
            <h1 class="heading-m" class="py-1">Experience</h1>

            <ul style=" list-style-type: none;">

              <li>
                <div class="experience-col" >
                  <img src="img/facebook-research.png" alt="FBAI" />
                  <div class="experience-informations">
                      <p>
                        <span class="bold"><a href="https://www.scs.cmu.edu/">School of Computer Science</a>, <a href="https://www.cmu.edu/">, Carnegie Mellon University</a></span>
                      </p>
                      <p>
                        Undergraduate Research Assistant, June 2020 – November 2020
                      </p>
                      <p>
                        Mentor: <a href="http://www.casos.cs.cmu.edu/bios/carley/carley.html" >Kathleen M. Carley</a>
                      </p>
                      <p>
                        Topic: Working under Prof. Dr. Kathleen M. Carley on Fine-grained classification and inference task for Tweets misinformation during the Covid-19 outbreak.
                      </p>
                  </div>
                </div>
              </li>

              <li>
                <div class="experience-col" >
                  <img src="img/Seal_of_University_of_California,_Berkeley.svg.png" alt="NTU, Singapore"/>
                  <div class="experience-informations">
                      <p>
                        <span class="bold"><a href="https://eecs.berkeley.edu/">EECS</a>, University of California, Berkeley</span>
                      </p>
                      <p>
                        Undergraduate Research Assistant, May. 2020 – November 2020
                      </p>
                      <p>
                        Mentor: <a href="https://people.eecs.berkeley.edu/~keutzer/" >Prof. Kurt Keutzer</a>
                      </p>
                      <p>
                        Topic: Working under Prof. Kurt Keutzer on low resource language Sanskrit for word segmentation task.
                      </p>
                  </div>
                </div>
              </li>
              <li>
                <div class="experience-col" >
                  <img src="img/academias.svg.png" alt="Academia Sinica, Taiwan" />
                  <div class="experience-informations">
                      <p>
                        <span class="bold"><a href="http://www.iitp.ac.in/~ai-nlp-ml/">AI-ML-NLP Lab</a>,Indian Institute of Technology, Patna</span>
                      </p>
                      <p>
                        Winter Research Intern, December 2019 – February 2020
                      </p>
                      <p>
                        Mentor: <a href="http://www.iitp.ac.in/~sriparna/" >Prof. Sriparna Saha</a>
                      </p>
                      <p>
                        Topic: Working at AI-ML-NLP lab under Prof. Dr Sriparna Saha for developing a deep learning multi-model framework for the protein-protein interaction model using protein sequence and 3D protein structure
                      </p>
                  </div>
                </div>
              </li>
              <li>
                <div class="experience-col" >
                  <img src="img/1200px-CNRS.svg.png" alt="Indraprastha Institute of Information Technology, Delhi"/>
                  <div class="experience-informations">
                      <p>
                        <span class="bold"><a href="http://www.liglab.fr/en/research/research-areas-and-teams/hadas" >Université Grenoble Alpes </a>, CNRS, LIG</span>
                      </p>
                      <p>
                        Summer Research Assistant, May 2019 —July 2019
                      </p>
                      <p>
                        Mentor: <a href="http://vargas-solar.com/" >Prof. PGenoveva Vargas Solar</a>
                      </p>
                      <p>
                        Topic: Worked with HADAS Team of LIG under the supervision of Dr. Genoveva Vargas Solar on developing a human-guided data exploration approach for efficiently extracting knowledge from disaster dataset (micro-blogs) based on a given user-generated query.
                      </p>
                  </div>
                </div>
              </li>
            </ul>
          </div>
          <div class="awards">
            <h1 class="heading-m py-1"></h1>
            <h1 class="heading-m" class="py-1">Awards and Recognition</h1>
            <ul>
              <li>Recipient of visiting scholar fellowship at Sorbonne University, Paris, Frace. Fully funded research internship under the supervision of Dr Prof. Antoine Mine at APR Team of LIP-6 Lab(CNRS).</li>
              <li>Received ICML 2020 registration grant as a support for attending and presenting my work at the ICML 2020</li>
              <li>Received NIPS 2020 registration grant as a support for attending and presenting my work at the NIPS 2020</li>
              <li>Virtually presented our work "COVID-19 question-answering exploration system" at the LIG-CNRS workshop on databases and information systems.</li>
              <li>Recognized on the university’s website as young research scholar on the recommendation of Institute Director</li>
              <li>Received a special mention for excellence in research and abroad internship in the yearly university magazine</li>
              <li>Start-Up idea accepted for presentation at the annual start-up summit "National Seminar on Pragmatic Role of Technological Innovation in Start-Up NPTIS-2020" organized by the government of India.</li>
              <li>Developed and deployed Google assistant service for Google console that was used worldwide for promoting E-Learning</li>
             <li>Selected as Microsoft Student Partner for the year 2019-2020. Conducted seminar and workshop for creating awareness</li>
              <li>Actively participated in competitive coding contest and data science competitions. Six start coder on HackaRank platform and Kaggle competitions contributor</li>		  
            </ul>
            <div class="service">

              <h1 class="heading-m" class="py-1">On-Source Contribution</h1>
              <ul>
                <li>

                    Contributed to HuggingFace pretrained models:
                    <a href="https://huggingface.co/rajratnpranesh"
                      >Trained BERT-base and RoBERTa language model from scratch using Sanskrit DCS corpus in IAST and SLP1 format. Models were published.</a
                    >
                    [August 2020 – October 2020]

                </li>
                <li>

                    Google Code-In Mentor-TensorFlow:
                    <a href="https://codein.withgoogle.com/archive/"
                      >Selected as mentor by Paige Bailey for the TensorFlow organization to supervise and guide young students in the field of Deep Learning and Open Source Community through TensorFlow</a
                    >
                    [November 2019 — January 2020]

                </li>
              </ul>
            </div>
          </div>
          <div class="service">
            <h1 class="heading-m" class="py-1">Technical Skills</h1>
            <ul>
              <li><span class="bold">Languages:</span> Java, Python, C/C++, Ocaml, SQL, HTML/CSS, LATEX</li>
              <li><span class="bold">Scientific Libraries:</span> TensorFlow, Keras, PyTorch Sklearn, Pandas, Numpy, NLTK</li>
              <li><span class="bold">Developer Tools:</span> Git, Google Cloud Platform, VS Code, Google Colab, Terminal, Android Studio</li>
            </ul>
          </div>


        <div id="suggestedlinks" class="suggestedlinks">
          <h1 class="heading-m py-1"></h1>
          <h1 class="heading-m py-1">Interesting Blogs</h1>
          <ul>
            <li><a href="https://www.csee.umbc.edu/~mariedj/papers/advice.pdf">How to Succeed in Graduate School: A Guide for Students and Advisors</a></li>
            <li><a href="http://martiansideofthemoon.github.io/2018/05/29/grad-resources.html">Grad School Resources</a></li>
            <li><a href="https://acl2017.wordpress.com/2017/02/23/last-minute-reviewing-advice/amp/?__twitter_impression=true">Last minute reviewing advice</a></li>
            <li><a href="https://towardsdatascience.com/how-you-should-read-research-papers-according-to-andrew-ng-stanford-deep-learning-lectures-98ecbd3ccfb3">How You Should Read Research Papers</a></li>
            <li><a href="https://arxiv.org/abs/1807.03341">Troubling Trends in Machine Learning Scholarship</a></li>
          </ul>

        </div>
        </div>
      </div>

      </section>
    </main>
  </body>
  <script src="https://unpkg.com/feather-icons"></script>
  <script src="js/main.js"></script>
</html>
